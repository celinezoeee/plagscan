= Plagiatscanner
:toc-titel: Inhalt
:toc: auto
:icons: font
:srcdir: .

== Ideensammlungen

=== Framework
Kivy -> funktioniert nur wenn man phyton downgradet auf 3.11.6 statt auf den neuesten stand
https://kivy.org/

QT -> https://doc.qt.io/qtforpython-6/quickstart.html#quick-start


=== Implementierung
Der Plagiatscanner soll:
+ zwei Files seperat einlesen können.
https://www.geeksforgeeks.org/python-file-chooser-in-kivy/


+für andere funktionen hier die tutorials:
https://www.geeksforgeeks.org/kivy-tutorial/

    -> + einen ladebalken?
        https://kivy.org/doc/stable/api-kivy.uix.progressbar.html
        https://www.geeksforgeeks.org/python-progress-bar-widget-in-kivy/



+ schöneres DESIGN mit KivyMD = https://kivymd.readthedocs.io/en/1.1.1/
    -ladebalken, ..
    

+ dann die ähnlichkeit in % ausgeben (berechnungen)

+ wenn ich einen file anklicke -> auch das ich es öffnen kann 

+popup fenster -> https://kivy.org/doc/stable/api-kivy.uix.popup.html
    --> wurde jetzt ein dialog fenster (ist schöner) = https://kivymd.readthedocs.io/en/latest/components/dialog/


+der vergleicht nur DOC, DOCX und PDF. Mit der Bibliothek kann man Dokumente vergleichen und die Änderungen sogar auf Zeichenebene verfolgen.
https://blog.aspose.com/de/words/compare-pdf-files-in-python/

+coding:
    - https://www.youtube.com/watch?v=tBqYSzy80xY
    - https://numpy.org/
            -- https://www.youtube.com/watch?v=nAcsuWBIwMo
    - https://www.youtube.com/watch?v=DIxxz_DvqLA
    - https://scikit-learn.org/stable/ 


-- zum updaten requirements.txt ->      pip freeze > requirements.txt

== Was noch zu tun ist (Stand 09.01.2023):
    - Preprocessing Funktion machen -> done
    - Logos kleiner machen -> done
    - evtl kleines Logo im Eck oben fixen -> done
    - evtl Bar in Lila einfärben
    - testen
    - fehlersuchen und fixen
    - File richtig umbenennen
    - KOMMENTIEREN !!!


== Random Braindump zum Code, Metriken etc.

scikit-learn installieren hat nicht funktioniert

https://medium.com/activewizards-machine-learning-company/comparison-of-the-text-distance-metrics-aed2eadfd1f1
jaccard similarity, cosinus similarity --> casesensitive
levenstein distanz
smith waterman algorithmus

verschiedene preprocessing stufen --> verschiedene similaritys berechen --> mittelwert
    groß/klein schreibung
    variablen weg

länge von File Buchstaben zählen
ausgabe: wert für jede metrik (und groß/klein?) und zusätzlich mittelwert


=== JACCARD SIMILARITY

from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
def calculate_jaccard_similarity(text1, text2):
    tokens1 = set(word_tokenize(text1.lower()))
    tokens2 = set(word_tokenize(text2.lower()))
    intersection = len(tokens1.intersection(tokens2))
    union = len(tokens1.union(tokens2))
    jaccard_sim = intersection / union if union > 0 else 0
    return jaccard_sim

=== LEVENSHTEIN DISTANZ

def levenshtein_distance(s1, s2):
    if len(s1) < len(s2):
        return levenshtein_distance(s2, s1)

    if len(s2) == 0:
        return len(s1)

    previous_row = range(len(s2) + 1)

    for i, c1 in enumerate(s1):
        current_row = [i + 1]

        for j, c2 in enumerate(s2):
            insertions = previous_row[j + 1] + 1
            deletions = current_row[j] + 1
            substitutions = previous_row[j] + (c1 != c2)

            current_row.append(min(insertions, deletions, substitutions))

        previous_row = current_row

    return previous_row[-1]

def levenshtein_similarity(text1, text2):
    max_length = max(len(text1), len(text2))
    distance = levenshtein_distance(text1, text2)
    similarity = 1 - (distance / max_length)
    return similarity



=== SMITH WATERMAN ALGORITHMUS

def smith_waterman_similarity(text1, text2):
    def max_substring_length(matrix):
        return max(max(row) for row in matrix)

    def backtrack(matrix, text1, text2, i, j):
        alignment1, alignment2 = '', ''

        while i > 0 and j > 0:
            if matrix[i][j] == matrix[i - 1][j - 1] + 1:
                alignment1 = text1[i - 1] + alignment1
                alignment2 = text2[j - 1] + alignment2
                i -= 1
                j -= 1
            elif matrix[i][j] == matrix[i - 1][j]:
                i -= 1
            else:
                j -= 1

        return alignment1, alignment2

    matrix = [[0] * (len(text2) + 1) for _ in range(len(text1) + 1)]

    for i in range(1, len(text1) + 1):
        for j in range(1, len(text2) + 1):
            if text1[i - 1] == text2[j - 1]:
                matrix[i][j] = matrix[i - 1][j - 1] + 1
            else:
                matrix[i][j] = max(matrix[i - 1][j], matrix[i][j - 1], matrix[i - 1][j - 1])

    max_len = max_substring_length(matrix)
    similarity = max_len / max(len(text1), len(text2))

    return similarity


=== COSINE SIMILARITY
import math

def cosine_similarity(text1, text2):
    def get_word_vector(text):
        words = text.lower().split()
        word_vector = {}
        for word in words:
            word_vector[word] = word_vector.get(word, 0) + 1
        return word_vector

    vector1 = get_word_vector(text1)
    vector2 = get_word_vector(text2)

    dot_product = sum(vector1[word] * vector2.get(word, 0) for word in vector1)
    magnitude1 = math.sqrt(sum(vector1[word] ** 2 for word in vector1))
    magnitude2 = math.sqrt(sum(vector2[word] ** 2 for word in vector2))

    similarity = dot_product / (magnitude1 * magnitude2) if magnitude1 > 0 and magnitude2 > 0 else 0
    return similarity


=== JACCARD SIMILARITY
def jaccard_similarity(text1, text2):
    set1 = set(text1.lower().split())
    set2 = set(text2.lower().split())

    intersection = len(set1.intersection(set2))
    union = len(set1.union(set2))

    similarity = intersection / union if union > 0 else 0
    return similarity


===





